"""
Working Memory Hygiene System
Canonical Spec Reference: Section 6.3.9 - Second Brain Hygiene

Automates cleanup and organization of working memory to prevent cognitive clutter.
Runs daily and weekly maintenance tasks.
"""

import logging
import json
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class OpenLoop:
    """Represents an item in open_loops.json"""
    id: str
    title: str
    created_at: str
    last_touched: str
    status: str  # 'active', 'stale', 'resolved'
    priority: str  # 'high', 'medium', 'low'
    context: str
    
    
@dataclass
class Decision:
    """Represents a decision from decisions.json"""
    id: str
    timestamp: str
    question: str
    decision: str
    reasoning: str
    outcome: Optional[str] = None


class WorkingMemoryHygiene:
    """
    Manages automated cleanup and organization of working memory
    Canonical Spec Section 6.3.9
    """
    
    def __init__(self, working_dir: Optional[Path] = None, archive_dir: Optional[Path] = None):
        self.working_dir = working_dir or Path("data/working")
        self.archive_dir = archive_dir or Path("data/archive/working")
        
        # Ensure directories exist
        self.working_dir.mkdir(parents=True, exist_ok=True)
        self.archive_dir.mkdir(parents=True, exist_ok=True)
        
        self.last_daily_reset = None
        self.last_weekly_review = None
        
    def daily_morning_reset(self) -> Dict:
        """
        Canonical Spec Section 6.3.9: Daily Morning Reset
        
        - Archive working/now.md → archive/working/now_YYYYMMDD.md
        - Reset working/now.md with today's top 3 priorities
        
        Returns:
            Summary of actions taken
        """
        logger.info("Starting daily morning reset...")
        
        actions = []
        today = datetime.now()
        date_str = today.strftime("%Y%m%d")
        
        # Archive yesterday's now.md
        now_file = self.working_dir / "now.md"
        if now_file.exists():
            archive_file = self.archive_dir / f"now_{date_str}.md"
            shutil.copy2(now_file, archive_file)
            actions.append(f"Archived now.md to {archive_file}")
            logger.info(f"Archived: {now_file} → {archive_file}")
        
        # Reset now.md with template
        reset_content = self._generate_daily_template(today)
        now_file.write_text(reset_content)
        actions.append("Reset now.md with today's template")
        logger.info("Reset now.md with fresh template")
        
        # Update last reset timestamp
        self.last_daily_reset = today.isoformat()
        
        return {
            'type': 'daily_reset',
            'timestamp': today.isoformat(),
            'actions': actions,
            'status': 'complete'
        }
    
    def _generate_daily_template(self, date: datetime) -> str:
        """Generate the daily now.md template"""
        day_name = date.strftime("%A")
        date_str = date.strftime("%B %d, %Y")
        
        template = f"""# Today: {day_name}, {date_str}

## Top 3 Priorities
1. 
2. 
3. 

## Energy Level
- Morning: 
- Afternoon: 
- Evening: 

## Focus Areas
- 

## Open Loops to Close
- 

## Notes & Reflections
- 

---
*Generated by Working Memory Hygiene System*
*Last updated: {datetime.now().strftime("%H:%M")}*
"""
        return template
    
    def weekly_review(self) -> Dict:
        """
        Canonical Spec Section 6.3.9: Weekly Review
        
        - Mark items in working/open_loops.json older than 7 days as stale: true
        - Propose: close, defer, or convert to decision
        
        Returns:
            Summary of stale items and recommendations
        """
        logger.info("Starting weekly review...")
        
        today = datetime.now()
        seven_days_ago = today - timedelta(days=7)
        
        actions = []
        recommendations = []
        
        # Process open loops
        open_loops_file = self.working_dir / "open_loops.json"
        if open_loops_file.exists():
            with open(open_loops_file, 'r') as f:
                data = json.load(f)
            
            loops = data.get('loops', [])
            stale_count = 0
            
            for loop in loops:
                last_touched = datetime.fromisoformat(loop.get('last_touched', today.isoformat()))
                
                if last_touched < seven_days_ago and loop.get('status') == 'active':
                    loop['status'] = 'stale'
                    stale_count += 1
                    
                    # Generate recommendation
                    recommendation = self._generate_recommendation(loop)
                    recommendations.append(recommendation)
            
            # Save updated loops
            if stale_count > 0:
                with open(open_loops_file, 'w') as f:
                    json.dump(data, f, indent=2)
                actions.append(f"Marked {stale_count} open loops as stale")
                logger.info(f"Marked {stale_count} loops as stale")
        
        # Update last review timestamp
        self.last_weekly_review = today.isoformat()
        
        return {
            'type': 'weekly_review',
            'timestamp': today.isoformat(),
            'actions': actions,
            'stale_items_found': len(recommendations),
            'recommendations': recommendations,
            'status': 'complete'
        }
    
    def _generate_recommendation(self, loop: Dict) -> Dict:
        """Generate recommendation for a stale loop"""
        # Simple heuristic-based recommendations
        priority = loop.get('priority', 'medium')
        created = datetime.fromisoformat(loop.get('created_at', datetime.now().isoformat()))
        age_days = (datetime.now() - created).days
        
        if priority == 'low' and age_days > 14:
            action = 'close'
            reason = 'Low priority, untouched for 2+ weeks'
        elif priority == 'high':
            action = 'escalate'
            reason = 'High priority but stale - needs immediate attention'
        elif age_days > 30:
            action = 'close_or_convert'
            reason = 'Very old - close if irrelevant, or convert to long-term project'
        else:
            action = 'defer'
            reason = 'Defer to next week if still relevant'
        
        return {
            'loop_id': loop.get('id'),
            'loop_title': loop.get('title'),
            'age_days': age_days,
            'recommended_action': action,
            'reason': reason
        }
    
    def rotate_decision_log(self, max_size_mb: float = 1.0) -> Dict:
        """
        Canonical Spec Section 6.3.9: Decision Log Rotation
        
        - Append working/decisions.json → heritage/decisions_log.md
        - Rotate if > max_size_mb (default 1MB)
        
        Args:
            max_size_mb: Maximum size in MB before rotation
            
        Returns:
            Summary of rotation action
        """
        logger.info("Checking decision log for rotation...")
        
        decisions_file = self.working_dir / "decisions.json"
        if not decisions_file.exists():
            return {
                'type': 'decision_rotation',
                'status': 'skipped',
                'reason': 'decisions.json does not exist'
            }
        
        # Check file size
        file_size_mb = decisions_file.stat().st_size / (1024 * 1024)
        
        if file_size_mb < max_size_mb:
            return {
                'type': 'decision_rotation',
                'status': 'skipped',
                'reason': f'File size ({file_size_mb:.2f}MB) below threshold ({max_size_mb}MB)'
            }
        
        # Perform rotation
        with open(decisions_file, 'r') as f:
            decisions_data = json.load(f)
        
        decisions = decisions_data.get('decisions', [])
        
        # Append to heritage log
        heritage_log = Path("data/heritage/decisions_log.md")
        heritage_log.parent.mkdir(parents=True, exist_ok=True)
        
        with open(heritage_log, 'a') as f:
            f.write(f"\n\n## Rotated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for decision in decisions:
                f.write(f"### {decision.get('timestamp')}\n")
                f.write(f"**Question**: {decision.get('question')}\n\n")
                f.write(f"**Decision**: {decision.get('decision')}\n\n")
                f.write(f"**Reasoning**: {decision.get('reasoning')}\n\n")
                if decision.get('outcome'):
                    f.write(f"**Outcome**: {decision.get('outcome')}\n\n")
                f.write("---\n\n")
        
        # Clear or archive the decisions.json
        archive_file = self.archive_dir / f"decisions_{datetime.now().strftime('%Y%m%d')}.json"
        shutil.copy2(decisions_file, archive_file)
        
        # Reset decisions.json
        with open(decisions_file, 'w') as f:
            json.dump({'decisions': [], 'rotated_at': datetime.now().isoformat()}, f, indent=2)
        
        logger.info(f"Rotated {len(decisions)} decisions to {heritage_log}")
        
        return {
            'type': 'decision_rotation',
            'status': 'complete',
            'decisions_rotated': len(decisions),
            'file_size_mb': file_size_mb,
            'archived_to': str(archive_file),
            'appended_to': str(heritage_log)
        }
    
    def cleanup_temp_files(self, max_age_days: int = 7) -> Dict:
        """
        Clean up temporary files older than max_age_days
        
        Args:
            max_age_days: Maximum age in days before deletion
            
        Returns:
            Summary of cleanup actions
        """
        logger.info(f"Cleaning up temp files older than {max_age_days} days...")
        
        temp_patterns = ['*.tmp', '*.temp', '*~', '.DS_Store']
        deleted_files = []
        
        for pattern in temp_patterns:
            for file in self.working_dir.rglob(pattern):
                try:
                    age_days = (datetime.now() - datetime.fromtimestamp(file.stat().st_mtime)).days
                    if age_days > max_age_days:
                        file.unlink()
                        deleted_files.append(str(file))
                        logger.info(f"Deleted temp file: {file}")
                except Exception as e:
                    logger.error(f"Error deleting {file}: {e}")
        
        return {
            'type': 'temp_cleanup',
            'files_deleted': len(deleted_files),
            'deleted_files': deleted_files,
            'status': 'complete'
        }
    
    def run_full_maintenance(self) -> Dict:
        """
        Run all maintenance tasks
        
        Returns:
            Summary of all tasks performed
        """
        logger.info("Running full working memory maintenance...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'tasks': []
        }
        
        # Daily reset
        daily_result = self.daily_morning_reset()
        results['tasks'].append(daily_result)
        
        # Weekly review
        weekly_result = self.weekly_review()
        results['tasks'].append(weekly_result)
        
        # Decision log rotation
        rotation_result = self.rotate_decision_log()
        results['tasks'].append(rotation_result)
        
        # Temp file cleanup
        cleanup_result = self.cleanup_temp_files()
        results['tasks'].append(cleanup_result)
        
        results['status'] = 'complete'
        results['summary'] = f"Completed {len(results['tasks'])} maintenance tasks"
        
        logger.info("Full maintenance complete")
        
        return results


# Global hygiene manager
hygiene_manager = WorkingMemoryHygiene()


def get_hygiene_manager() -> WorkingMemoryHygiene:
    """Get the global hygiene manager"""
    return hygiene_manager


def schedule_daily_reset():
    """
    Schedule the daily reset to run every morning
    This should be called from the main server startup
    """
    # This would integrate with a scheduler like APScheduler
    # For now, it's a placeholder for the integration point
    logger.info("Daily reset scheduler initialized")


def schedule_weekly_review():
    """
    Schedule the weekly review to run every Sunday evening
    This should be called from the main server startup
    """
    # This would integrate with a scheduler like APScheduler
    # For now, it's a placeholder for the integration point
    logger.info("Weekly review scheduler initialized")
