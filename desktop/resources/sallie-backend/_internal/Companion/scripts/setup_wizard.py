#!/usr/bin/env python3
"""
Interactive setup wizard for Digital Progeny.
Guides users through initial configuration.
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any, Optional

def print_header(text: str):
    """Print a formatted header."""
    print("\n" + "=" * 60)
    print(text)
    print("=" * 60)

def print_section(text: str):
    """Print a section header."""
    print(f"\n{text}")
    print("-" * 60)

def ask_yes_no(prompt: str, default: bool = True) -> bool:
    """Ask a yes/no question."""
    default_str = "Y/n" if default else "y/N"
    response = input(f"{prompt} [{default_str}]: ").strip().lower()
    
    if not response:
        return default
    
    return response.startswith('y')

def ask_string(prompt: str, default: Optional[str] = None, required: bool = True) -> str:
    """Ask for a string input."""
    default_str = f" (default: {default})" if default else ""
    required_str = " (required)" if required else ""
    
    while True:
        response = input(f"{prompt}{default_str}{required_str}: ").strip()
        
        if response:
            return response
        elif default:
            return default
        elif not required:
            return ""
        else:
            print("  This field is required. Please enter a value.")

def ask_choice(prompt: str, choices: list, default: Optional[int] = None) -> int:
    """Ask user to choose from a list."""
    print(f"\n{prompt}")
    for i, choice in enumerate(choices, 1):
        marker = " [default]" if default == i else ""
        print(f"  {i}. {choice}{marker}")
    
    while True:
        try:
            response = input(f"Choice [1-{len(choices)}]: ").strip()
            if not response and default:
                return default
            
            choice_num = int(response)
            if 1 <= choice_num <= len(choices):
                return choice_num
            else:
                print(f"Please enter a number between 1 and {len(choices)}")
        except ValueError:
            print("Please enter a valid number")

def check_dependencies():
    """Check if dependencies are installed."""
    print_section("Checking Dependencies")
    
    # Check Python version
    if sys.version_info < (3, 11):
        print(f"✗ Python version {sys.version_info.major}.{sys.version_info.minor} is too old (3.11+ required)")
        return False
    print(f"✓ Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")
    
    # Check Node.js
    try:
        import subprocess
        result = subprocess.run(["node", "--version"], capture_output=True, timeout=5)
        if result.returncode == 0:
            print(f"✓ Node.js {result.stdout.decode().strip()}")
        else:
            print("✗ Node.js not found")
            return False
    except Exception:
        print("✗ Node.js not found")
        return False
    
    # Check Docker (optional)
    try:
        result = subprocess.run(["docker", "--version"], capture_output=True, timeout=5)
        if result.returncode == 0:
            print(f"✓ Docker {result.stdout.decode().strip()}")
        else:
            print("⚠ Docker not found (optional)")
    except Exception:
        print("⚠ Docker not found (optional)")
    
    return True

def create_env_file(config: Dict[str, Any]):
    """Create .env file from configuration."""
    env_path = Path(".env")
    
    env_content = f"""# Digital Progeny Environment Configuration
# Generated by setup wizard

# API Configuration
PROGENY_ROOT={config.get('progeny_root', './progeny_root')}
API_PORT={config.get('api_port', 8000)}
WEB_PORT={config.get('web_port', 3000)}

# Ollama Configuration
OLLAMA_URL={config.get('ollama_url', 'http://localhost:11434')}
OLLAMA_MODEL={config.get('ollama_model', 'deepseek-v3')}

# Qdrant Configuration
QDRANT_URL={config.get('qdrant_url', 'http://localhost:6333')}

# Logging
LOG_LEVEL={config.get('log_level', 'INFO')}

# Optional: Gemini API Key (leave empty to use Ollama only)
GEMINI_API_KEY={config.get('gemini_api_key', '')}
"""
    
    with open(env_path, "w", encoding="utf-8") as f:
        f.write(env_content)
    
    print(f"\n✓ Created .env file at {env_path.absolute()}")

def create_config_json(config: Dict[str, Any]):
    """Create or update config.json."""
    config_path = Path("progeny_root/core/config.json")
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Load existing config if it exists
    existing_config = {}
    if config_path.exists():
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                existing_config = json.load(f)
        except Exception:
            pass
    
    # Merge with new config
    existing_config.update({
        "ui": {
            "dashboard_port": config.get("web_port", 3000)
        },
        "llm": {
            "gemini_api_key": config.get("gemini_api_key", ""),
            "fallback_model": config.get("ollama_model", "deepseek-v3")
        },
        "endpoints": {
            "ollama": config.get("ollama_url", "http://localhost:11434"),
            "qdrant": config.get("qdrant_url", "http://localhost:6333")
        }
    })
    
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(existing_config, f, indent=2)
    
    print(f"✓ Updated config.json at {config_path.absolute()}")

def setup_directories():
    """Create required directories."""
    print_section("Setting Up Directories")
    
    directories = [
        "progeny_root/logs",
        "progeny_root/working",
        "progeny_root/drafts",
        "progeny_root/outbox",
        "progeny_root/archive",
        "progeny_root/memory",
        "progeny_root/limbic/heritage/history"
    ]
    
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"✓ {dir_path}")

def test_services(config: Dict[str, Any]):
    """Test if services are running."""
    print_section("Testing Services")
    
    import requests
    
    # Test Ollama
    ollama_url = config.get("ollama_url", "http://localhost:11434")
    try:
        response = requests.get(f"{ollama_url}/api/tags", timeout=5)
        if response.status_code == 200:
            print("✓ Ollama is running")
        else:
            print("⚠ Ollama responded with an error")
    except Exception:
        print("⚠ Ollama is not running (start with: ollama serve)")
    
    # Test Qdrant
    qdrant_url = config.get("qdrant_url", "http://localhost:6333")
    try:
        response = requests.get(f"{qdrant_url}/collections", timeout=5)
        if response.status_code == 200:
            print("✓ Qdrant is running")
        else:
            print("⚠ Qdrant responded with an error")
    except Exception:
        print("⚠ Qdrant is not running (start with Docker: docker run -p 6333:6333 qdrant/qdrant)")

def main():
    """Main setup wizard function."""
    print_header("Digital Progeny - Setup Wizard")
    
    print("\nWelcome! This wizard will help you configure Digital Progeny.")
    print("You can press Enter to accept defaults (shown in brackets).")
    
    if not ask_yes_no("\nDo you want to continue?", default=True):
        print("\nSetup cancelled.")
        return 0
    
    # Check dependencies
    if not check_dependencies():
        print("\n[ERROR] Please install missing dependencies and run the wizard again.")
        return 1
    
    # Collect configuration
    config = {}
    
    print_header("Configuration")
    
    config["progeny_root"] = ask_string(
        "Progeny root directory",
        default="./progeny_root",
        required=False
    )
    
    config["api_port"] = int(ask_string(
        "API server port",
        default="8000",
        required=False
    ))
    
    config["web_port"] = int(ask_string(
        "Web UI port",
        default="3000",
        required=False
    ))
    
    config["ollama_url"] = ask_string(
        "Ollama URL",
        default="http://localhost:11434",
        required=False
    )
    
    config["ollama_model"] = ask_string(
        "Ollama model name",
        default="deepseek-v3",
        required=False
    )
    
    config["qdrant_url"] = ask_string(
        "Qdrant URL",
        default="http://localhost:6333",
        required=False
    )
    
    config["log_level"] = ask_choice(
        "Log level",
        ["DEBUG", "INFO", "WARNING", "ERROR"],
        default=2
    )
    config["log_level"] = ["DEBUG", "INFO", "WARNING", "ERROR"][config["log_level"] - 1]
    
    # Optional: Gemini API key
    print_section("Optional: Gemini API Key")
    if ask_yes_no("Do you want to configure Gemini API key?", default=False):
        config["gemini_api_key"] = ask_string(
            "Gemini API key",
            required=False
        )
    else:
        config["gemini_api_key"] = ""
    
    # Create files
    print_header("Creating Configuration Files")
    
    create_env_file(config)
    create_config_json(config)
    setup_directories()
    
    # Test services
    if ask_yes_no("\nDo you want to test service connections?", default=True):
        test_services(config)
    
    # Final instructions
    print_header("Setup Complete!")
    
    print("\nNext steps:")
    print("1. Ensure Ollama and Qdrant are running")
    print("2. Start the main server:")
    print("   python -m uvicorn core.main:app --reload --port", config["api_port"])
    print("3. Start the web UI (in another terminal):")
    print("   cd web && npm run dev")
    print("4. Open http://localhost:" + str(config["web_port"]))
    print("5. Complete the Convergence process (15 questions)")
    print("\nFor more help, see: progeny_root/README.md")
    
    return 0

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nSetup cancelled by user.")
        sys.exit(1)

